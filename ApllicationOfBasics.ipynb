{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b571488d-0404-4072-a6fc-60475d3f975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Requirement already satisfied: pymupdf in /home/c4aa6a31-8778-4e79-96de-ab90cdd4435a/.local/lib/python3.10/site-packages (1.25.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d837a95-b991-4b0e-b506-6a1b5b71a6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have had the good fortune to study under Miss Arpita Mukherjee for over three years now. I \n",
      "am sure I owe this to her teaching and utmost patience for my 98 marks in my ISC Board \n",
      "exams. Arpita ma’am is truly blessed with good subject matter knowledge and just makes \n",
      "English so alive. \n",
      "She seamlessly intermingles examples of life, her own life experience, real issues of the \n",
      "world, even historical facts in her lectures and interlaces them within her excellent oratory \n",
      "skills to make complex ideas lucid and amusing to acquire. Learning wasn't so much in the \n",
      "form of a structured lecture but a thrilling discussion which I always looked forward to. Her \n",
      "way of tying literature and language to everyday life made it convenient and interesting to \n",
      "learn. \n",
      "Never would this success be given without her constant guidance, encouragement, and \n",
      "relentless efforts. I shall always be indebted to her and feel privileged to have been with her \n",
      "as a pupil. Thank you so much, ma'am, from the bottom of my heart. \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import nltk\n",
    "\n",
    "doc = fitz.open(\"Testimonial.pdf\")\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "for page in doc:\n",
    "    text = text+page.get_text()  \n",
    "\n",
    "doc.close()  \n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37229daf-35e2-46d0-b0b7-5984c886d279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'had', 'the', 'good', 'fortune', 'to', 'study', 'under', 'Miss', 'Arpita', 'Mukherjee', 'for', 'over', 'three', 'years', 'now', '.', 'I', 'am', 'sure', 'I', 'owe', 'this', 'to', 'her', 'teaching', 'and', 'utmost', 'patience', 'for', 'my', '98', 'marks', 'in', 'my', 'ISC', 'Board', 'exams', '.', 'Arpita', 'ma', '’', 'am', 'is', 'truly', 'blessed', 'with', 'good', 'subject', 'matter', 'knowledge', 'and', 'just', 'makes', 'English', 'so', 'alive', '.', 'She', 'seamlessly', 'intermingles', 'examples', 'of', 'life', ',', 'her', 'own', 'life', 'experience', ',', 'real', 'issues', 'of', 'the', 'world', ',', 'even', 'historical', 'facts', 'in', 'her', 'lectures', 'and', 'interlaces', 'them', 'within', 'her', 'excellent', 'oratory', 'skills', 'to', 'make', 'complex', 'ideas', 'lucid', 'and', 'amusing', 'to', 'acquire', '.', 'Learning', 'was', \"n't\", 'so', 'much', 'in', 'the', 'form', 'of', 'a', 'structured', 'lecture', 'but', 'a', 'thrilling', 'discussion', 'which', 'I', 'always', 'looked', 'forward', 'to', '.', 'Her', 'way', 'of', 'tying', 'literature', 'and', 'language', 'to', 'everyday', 'life', 'made', 'it', 'convenient', 'and', 'interesting', 'to', 'learn', '.', 'Never', 'would', 'this', 'success', 'be', 'given', 'without', 'her', 'constant', 'guidance', ',', 'encouragement', ',', 'and', 'relentless', 'efforts', '.', 'I', 'shall', 'always', 'be', 'indebted', 'to', 'her', 'and', 'feel', 'privileged', 'to', 'have', 'been', 'with', 'her', 'as', 'a', 'pupil', '.', 'Thank', 'you', 'so', 'much', ',', \"ma'am\", ',', 'from', 'the', 'bottom', 'of', 'my', 'heart', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenization = nltk.word_tokenize(text)\n",
    "print(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2caeb77-bcb1-4d99-afb1-f8b97866dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'have', 'had', 'the', 'good', 'fortun', 'to', 'studi', 'under', 'miss', 'arpita', 'mukherje', 'for', 'over', 'three', 'year', 'now', '.', 'i', 'am', 'sure', 'i', 'owe', 'thi', 'to', 'her', 'teach', 'and', 'utmost', 'patienc', 'for', 'my', '98', 'mark', 'in', 'my', 'isc', 'board', 'exam', '.', 'arpita', 'ma', '’', 'am', 'is', 'truli', 'bless', 'with', 'good', 'subject', 'matter', 'knowledg', 'and', 'just', 'make', 'english', 'so', 'aliv', '.', 'she', 'seamlessli', 'intermingl', 'exampl', 'of', 'life', ',', 'her', 'own', 'life', 'experi', ',', 'real', 'issu', 'of', 'the', 'world', ',', 'even', 'histor', 'fact', 'in', 'her', 'lectur', 'and', 'interlac', 'them', 'within', 'her', 'excel', 'oratori', 'skill', 'to', 'make', 'complex', 'idea', 'lucid', 'and', 'amus', 'to', 'acquir', '.', 'learn', 'wa', \"n't\", 'so', 'much', 'in', 'the', 'form', 'of', 'a', 'structur', 'lectur', 'but', 'a', 'thrill', 'discuss', 'which', 'i', 'alway', 'look', 'forward', 'to', '.', 'her', 'way', 'of', 'tie', 'literatur', 'and', 'languag', 'to', 'everyday', 'life', 'made', 'it', 'conveni', 'and', 'interest', 'to', 'learn', '.', 'never', 'would', 'thi', 'success', 'be', 'given', 'without', 'her', 'constant', 'guidanc', ',', 'encourag', ',', 'and', 'relentless', 'effort', '.', 'i', 'shall', 'alway', 'be', 'indebt', 'to', 'her', 'and', 'feel', 'privileg', 'to', 'have', 'been', 'with', 'her', 'as', 'a', 'pupil', '.', 'thank', 'you', 'so', 'much', ',', \"ma'am\", ',', 'from', 'the', 'bottom', 'of', 'my', 'heart', '.']\n"
     ]
    }
   ],
   "source": [
    "porter1 = nltk.PorterStemmer()\n",
    "stemming1 = [porter1.stem(s1) for s1 in tokenization]\n",
    "print(stemming1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a153dec-dcd0-4f05-a9d8-d074087bb9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'have', 'had', 'the', 'good', 'fortun', 'to', 'studi', 'under', 'miss', 'arpita', 'mukherje', 'for', 'over', 'three', 'year', 'now', '.', 'i', 'am', 'sure', 'i', 'owe', 'thi', 'to', 'her', 'teach', 'and', 'utmost', 'patienc', 'for', 'my', '98', 'mark', 'in', 'my', 'isc', 'board', 'exam', '.', 'arpita', 'ma', '’', 'am', 'is', 'truli', 'bless', 'with', 'good', 'subject', 'matter', 'knowledg', 'and', 'just', 'make', 'english', 'so', 'aliv', '.', 'she', 'seamlessli', 'intermingl', 'exampl', 'of', 'life', ',', 'her', 'own', 'life', 'experi', ',', 'real', 'issu', 'of', 'the', 'world', ',', 'even', 'histor', 'fact', 'in', 'her', 'lectur', 'and', 'interlac', 'them', 'within', 'her', 'excel', 'oratori', 'skill', 'to', 'make', 'complex', 'idea', 'lucid', 'and', 'amus', 'to', 'acquir', '.', 'learn', 'wa', \"n't\", 'so', 'much', 'in', 'the', 'form', 'of', 'a', 'structur', 'lectur', 'but', 'a', 'thrill', 'discuss', 'which', 'i', 'alway', 'look', 'forward', 'to', '.', 'her', 'way', 'of', 'tie', 'literatur', 'and', 'languag', 'to', 'everyday', 'life', 'made', 'it', 'conveni', 'and', 'interest', 'to', 'learn', '.', 'never', 'would', 'thi', 'success', 'be', 'given', 'without', 'her', 'constant', 'guidanc', ',', 'encourag', ',', 'and', 'relentless', 'effort', '.', 'i', 'shall', 'alway', 'be', 'indebt', 'to', 'her', 'and', 'feel', 'privileg', 'to', 'have', 'been', 'with', 'her', 'as', 'a', 'pupil', '.', 'thank', 'you', 'so', 'much', ',', \"ma'am\", ',', 'from', 'the', 'bottom', 'of', 'my', 'heart', '.']\n"
     ]
    }
   ],
   "source": [
    "porter2 = nltk.SnowballStemmer(language='english')\n",
    "stemming2 = [porter1.stem(s2) for s2 in tokenization]\n",
    "print(stemming2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96722a04-49c8-44ed-a307-773e87d37a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'have', 'had', 'the', 'good', 'fortun', 'to', 'studi', 'under', 'miss', 'arpita', 'mukherje', 'for', 'over', 'three', 'year', 'now', '.', 'i', 'am', 'sure', 'i', 'owe', 'thi', 'to', 'her', 'teach', 'and', 'utmost', 'patienc', 'for', 'my', '98', 'mark', 'in', 'my', 'isc', 'board', 'exam', '.', 'arpita', 'ma', '’', 'am', 'is', 'truli', 'bless', 'with', 'good', 'subject', 'matter', 'knowledg', 'and', 'just', 'make', 'english', 'so', 'aliv', '.', 'she', 'seamlessli', 'intermingl', 'exampl', 'of', 'life', ',', 'her', 'own', 'life', 'experi', ',', 'real', 'issu', 'of', 'the', 'world', ',', 'even', 'histor', 'fact', 'in', 'her', 'lectur', 'and', 'interlac', 'them', 'within', 'her', 'excel', 'oratori', 'skill', 'to', 'make', 'complex', 'idea', 'lucid', 'and', 'amus', 'to', 'acquir', '.', 'learn', 'wa', \"n't\", 'so', 'much', 'in', 'the', 'form', 'of', 'a', 'structur', 'lectur', 'but', 'a', 'thrill', 'discuss', 'which', 'i', 'alway', 'look', 'forward', 'to', '.', 'her', 'way', 'of', 'tie', 'literatur', 'and', 'languag', 'to', 'everyday', 'life', 'made', 'it', 'conveni', 'and', 'interest', 'to', 'learn', '.', 'never', 'would', 'thi', 'success', 'be', 'given', 'without', 'her', 'constant', 'guidanc', ',', 'encourag', ',', 'and', 'relentless', 'effort', '.', 'i', 'shall', 'alway', 'be', 'indebt', 'to', 'her', 'and', 'feel', 'privileg', 'to', 'have', 'been', 'with', 'her', 'as', 'a', 'pupil', '.', 'thank', 'you', 'so', 'much', ',', \"ma'am\", ',', 'from', 'the', 'bottom', 'of', 'my', 'heart', '.']\n"
     ]
    }
   ],
   "source": [
    "porter3 = nltk.LancasterStemmer()\n",
    "stemming3 = [porter1.stem(s3) for s3 in tokenization]\n",
    "print(stemming3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9186ccf3-e5b0-4c7d-b7d0-785295e6f854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'had', 'the', 'good', 'fortune', 'to', 'study', 'under', 'Miss', 'Arpita', 'Mukherjee', 'for', 'over', 'three', 'year', 'now', '.', 'I', 'am', 'sure', 'I', 'owe', 'this', 'to', 'her', 'teaching', 'and', 'utmost', 'patience', 'for', 'my', '98', 'mark', 'in', 'my', 'ISC', 'Board', 'exam', '.', 'Arpita', 'ma', '’', 'am', 'is', 'truly', 'blessed', 'with', 'good', 'subject', 'matter', 'knowledge', 'and', 'just', 'make', 'English', 'so', 'alive', '.', 'She', 'seamlessly', 'intermingles', 'example', 'of', 'life', ',', 'her', 'own', 'life', 'experience', ',', 'real', 'issue', 'of', 'the', 'world', ',', 'even', 'historical', 'fact', 'in', 'her', 'lecture', 'and', 'interlaces', 'them', 'within', 'her', 'excellent', 'oratory', 'skill', 'to', 'make', 'complex', 'idea', 'lucid', 'and', 'amusing', 'to', 'acquire', '.', 'Learning', 'wa', \"n't\", 'so', 'much', 'in', 'the', 'form', 'of', 'a', 'structured', 'lecture', 'but', 'a', 'thrilling', 'discussion', 'which', 'I', 'always', 'looked', 'forward', 'to', '.', 'Her', 'way', 'of', 'tying', 'literature', 'and', 'language', 'to', 'everyday', 'life', 'made', 'it', 'convenient', 'and', 'interesting', 'to', 'learn', '.', 'Never', 'would', 'this', 'success', 'be', 'given', 'without', 'her', 'constant', 'guidance', ',', 'encouragement', ',', 'and', 'relentless', 'effort', '.', 'I', 'shall', 'always', 'be', 'indebted', 'to', 'her', 'and', 'feel', 'privileged', 'to', 'have', 'been', 'with', 'her', 'a', 'a', 'pupil', '.', 'Thank', 'you', 'so', 'much', ',', \"ma'am\", ',', 'from', 'the', 'bottom', 'of', 'my', 'heart', '.']\n"
     ]
    }
   ],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "lemmatization = [wn.lemmatize(l1) for l1 in tokenization]\n",
    "print(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0248800b-3b3a-42b1-aa34-33576320689d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'good', 'fortune', 'study', 'Miss', 'Arpita', 'Mukherjee', 'three', 'years', '.', 'I', 'sure', 'I', 'owe', 'teaching', 'utmost', 'patience', '98', 'marks', 'ISC', 'Board', 'exams', '.', 'Arpita', '’', 'truly', 'blessed', 'good', 'subject', 'matter', 'knowledge', 'makes', 'English', 'alive', '.', 'She', 'seamlessly', 'intermingles', 'examples', 'life', ',', 'life', 'experience', ',', 'real', 'issues', 'world', ',', 'even', 'historical', 'facts', 'lectures', 'interlaces', 'within', 'excellent', 'oratory', 'skills', 'make', 'complex', 'ideas', 'lucid', 'amusing', 'acquire', '.', 'Learning', \"n't\", 'much', 'form', 'structured', 'lecture', 'thrilling', 'discussion', 'I', 'always', 'looked', 'forward', '.', 'Her', 'way', 'tying', 'literature', 'language', 'everyday', 'life', 'made', 'convenient', 'interesting', 'learn', '.', 'Never', 'would', 'success', 'given', 'without', 'constant', 'guidance', ',', 'encouragement', ',', 'relentless', 'efforts', '.', 'I', 'shall', 'always', 'indebted', 'feel', 'privileged', 'pupil', '.', 'Thank', 'much', ',', \"ma'am\", ',', 'bottom', 'heart', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "word = stopwords.words('english')\n",
    "text1 = [word1 for word1 in tokenization if not word1 in word]\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d158c0f-392e-4648-817e-149ccd94f644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have had the good fortune to study under miss arpita mukherjee for over three years now. i \n",
      "am sure i owe this to her teaching and utmost patience for my 98 marks in my isc board \n",
      "exams. arpita ma’am is truly blessed with good subject matter knowledge and just makes \n",
      "english so alive. \n",
      "she seamlessly intermingles examples of life, her own life experience, real issues of the \n",
      "world, even historical facts in her lectures and interlaces them within her excellent oratory \n",
      "skills to make complex ideas lucid and amusing to acquire. learning wasn't so much in the \n",
      "form of a structured lecture but a thrilling discussion which i always looked forward to. her \n",
      "way of tying literature and language to everyday life made it convenient and interesting to \n",
      "learn. \n",
      "never would this success be given without her constant guidance, encouragement, and \n",
      "relentless efforts. i shall always be indebted to her and feel privileged to have been with her \n",
      "as a pupil. thank you so much, ma'am, from the bottom of my heart. \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lowercase = text.lower()\n",
    "print(lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98bb2d31-2fe9-4668-875e-f53e6eaed23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I->PRP\n",
      "have->VBP\n",
      "had->VBD\n",
      "the->DT\n",
      "good->JJ\n",
      "fortune->NN\n",
      "to->TO\n",
      "study->VB\n",
      "under->IN\n",
      "Miss->NNP\n",
      "Arpita->NNP\n",
      "Mukherjee->NNP\n",
      "for->IN\n",
      "over->IN\n",
      "three->CD\n",
      "years->NNS\n",
      "now->RB\n",
      ".->.\n",
      "I->PRP\n",
      "am->VBP\n",
      "sure->JJ\n",
      "I->PRP\n",
      "owe->VBP\n",
      "this->DT\n",
      "to->TO\n",
      "her->PRP$\n",
      "teaching->NN\n",
      "and->CC\n",
      "utmost->JJ\n",
      "patience->NN\n",
      "for->IN\n",
      "my->PRP$\n",
      "98->CD\n",
      "marks->NNS\n",
      "in->IN\n",
      "my->PRP$\n",
      "ISC->NNP\n",
      "Board->NNP\n",
      "exams->VBZ\n",
      ".->.\n",
      "Arpita->NNP\n",
      "ma->NN\n",
      "’->NNP\n",
      "am->VBP\n",
      "is->VBZ\n",
      "truly->RB\n",
      "blessed->VBN\n",
      "with->IN\n",
      "good->JJ\n",
      "subject->JJ\n",
      "matter->NN\n",
      "knowledge->NN\n",
      "and->CC\n",
      "just->RB\n",
      "makes->VBZ\n",
      "English->NNP\n",
      "so->RB\n",
      "alive->JJ\n",
      ".->.\n",
      "She->PRP\n",
      "seamlessly->RB\n",
      "intermingles->VBZ\n",
      "examples->NNS\n",
      "of->IN\n",
      "life->NN\n",
      ",->,\n",
      "her->PRP$\n",
      "own->JJ\n",
      "life->NN\n",
      "experience->NN\n",
      ",->,\n",
      "real->JJ\n",
      "issues->NNS\n",
      "of->IN\n",
      "the->DT\n",
      "world->NN\n",
      ",->,\n",
      "even->RB\n",
      "historical->JJ\n",
      "facts->NNS\n",
      "in->IN\n",
      "her->PRP$\n",
      "lectures->NNS\n",
      "and->CC\n",
      "interlaces->NNS\n",
      "them->PRP\n",
      "within->IN\n",
      "her->PRP\n",
      "excellent->JJ\n",
      "oratory->JJ\n",
      "skills->NNS\n",
      "to->TO\n",
      "make->VB\n",
      "complex->JJ\n",
      "ideas->NNS\n",
      "lucid->NN\n",
      "and->CC\n",
      "amusing->VBG\n",
      "to->TO\n",
      "acquire->VB\n",
      ".->.\n",
      "Learning->NNP\n",
      "was->VBD\n",
      "n't->RB\n",
      "so->RB\n",
      "much->JJ\n",
      "in->IN\n",
      "the->DT\n",
      "form->NN\n",
      "of->IN\n",
      "a->DT\n",
      "structured->JJ\n",
      "lecture->NN\n",
      "but->CC\n",
      "a->DT\n",
      "thrilling->NN\n",
      "discussion->NN\n",
      "which->WDT\n",
      "I->PRP\n",
      "always->RB\n",
      "looked->VBD\n",
      "forward->RB\n",
      "to->TO\n",
      ".->.\n",
      "Her->PRP$\n",
      "way->NN\n",
      "of->IN\n",
      "tying->VBG\n",
      "literature->NN\n",
      "and->CC\n",
      "language->NN\n",
      "to->TO\n",
      "everyday->JJ\n",
      "life->NN\n",
      "made->VBD\n",
      "it->PRP\n",
      "convenient->JJ\n",
      "and->CC\n",
      "interesting->JJ\n",
      "to->TO\n",
      "learn->VB\n",
      ".->.\n",
      "Never->NNP\n",
      "would->MD\n",
      "this->DT\n",
      "success->NN\n",
      "be->VB\n",
      "given->VBN\n",
      "without->IN\n",
      "her->PRP\n",
      "constant->JJ\n",
      "guidance->NN\n",
      ",->,\n",
      "encouragement->NN\n",
      ",->,\n",
      "and->CC\n",
      "relentless->NN\n",
      "efforts->NNS\n",
      ".->.\n",
      "I->PRP\n",
      "shall->MD\n",
      "always->RB\n",
      "be->VB\n",
      "indebted->JJ\n",
      "to->TO\n",
      "her->PRP$\n",
      "and->CC\n",
      "feel->VB\n",
      "privileged->VBN\n",
      "to->TO\n",
      "have->VB\n",
      "been->VBN\n",
      "with->IN\n",
      "her->PRP\n",
      "as->IN\n",
      "a->DT\n",
      "pupil->NN\n",
      ".->.\n",
      "Thank->NNP\n",
      "you->PRP\n",
      "so->RB\n",
      "much->RB\n",
      ",->,\n",
      "ma'am->NNS\n",
      ",->,\n",
      "from->IN\n",
      "the->DT\n",
      "bottom->NN\n",
      "of->IN\n",
      "my->PRP$\n",
      "heart->NN\n",
      ".->.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/c4aa6a31-8778-4e79-96de-\n",
      "[nltk_data]     ab90cdd4435a/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "PosTag = nltk.pos_tag(tokenization)\n",
    "for i, j in PosTag:  \n",
    "    print(i + \"->\" + j)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b388859-075d-4211-b5d4-208c6be77276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 'thank you' in the text!\n",
      "Found 'arpita' in the text!\n"
     ]
    }
   ],
   "source": [
    "phrase1 = \"thank you\"\n",
    "if phrase1 in lowercase:\n",
    "    print(f\"Found '{phrase1}' in the text!\")\n",
    "phrase2 = \"arpita\"\n",
    "if phrase2 in lowercase:\n",
    "    print(f\"Found '{phrase2}' in the text!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
